{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"~\\\\bigcon_data_1.csv\", header=0,engine='python')\n",
    "data2 = pd.read_csv(\"~\\\\bigcon_data_2.csv\", header=0,engine='python')\n",
    "data3 = pd.read_csv(\"~\\\\bigcon_data_3.csv\", header=0,engine='python')\n",
    "data4 = pd.read_csv(\"~\\\\bigcon_data_4.csv\", header=0,engine='python')\n",
    "data5 = pd.read_csv(\"~\\\\bigcon_data_5.csv\", header=0,engine='python')\n",
    "data6 = pd.read_csv(\"~\\\\bigcon_data_6.csv\", header=0,engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prove similarity of correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average=pd.concat([data1[\"유역평균강수\"],data2[\"유역평균강수\"],data3[\"유역평균강수\"],data4[\"유역평균강수\"],data5[\"유역평균강수\"],data6[\"유역평균강수\"]], axis=1)\n",
    "rainA=pd.concat([data1[\"강우(A지역)\"],data2[\"강우(A지역)\"],data3[\"강우(A지역)\"],data4[\"강우(A지역)\"],data5[\"강우(A지역)\"],data6[\"강우(A지역)\"]], axis=1)\n",
    "rainB=pd.concat([data1[\"강우(B지역)\"],data2[\"강우(B지역)\"],data3[\"강우(B지역)\"],data4[\"강우(B지역)\"],data5[\"강우(B지역)\"],data6[\"강우(B지역)\"]], axis=1)\n",
    "rainC=pd.concat([data1[\"강우(C지역)\"],data2[\"강우(C지역)\"],data3[\"강우(C지역)\"],data4[\"강우(C지역)\"],data5[\"강우(C지역)\"],data6[\"강우(C지역)\"]], axis=1)\n",
    "rainD=pd.concat([data1[\"강우(D지역)\"],data2[\"강우(D지역)\"],data3[\"강우(D지역)\"],data4[\"강우(D지역)\"],data5[\"강우(D지역)\"],data6[\"강우(D지역)\"]], axis=1)\n",
    "heightE=pd.concat([data1[\"수위(E지역)\"],data2[\"수위(E지역)\"],data3[\"수위(E지역)\"],data4[\"수위(E지역)\"],data5[\"수위(E지역)\"],data6[\"수위(E지역)\"]], axis=1)\n",
    "heightD=pd.concat([data1[\"수위(D지역)\"],data2[\"수위(D지역)\"],data3[\"수위(D지역)\"],data4[\"수위(D지역)\"],data5[\"수위(D지역)\"],data6[\"수위(D지역)\"]], axis=1)\n",
    "\n",
    "average.corr();rainA.corr();rainB.corr();rainC.corr();rainD.corr();heightE.corr();heightD.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~\\\\bigcon_data_1.csv\", header=0,engine='python')\n",
    "\n",
    "pr=data.profile_report()\n",
    "data.profile_report()\n",
    "pr.to_file('./data1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.select_dtypes('object').columns:\n",
    "   le = LabelEncoder().fit(data[i])\n",
    "   data[i] = le.transform(data[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler()\n",
    "Y_scaler = MinMaxScaler()\n",
    "X_data = X_scaler.fit_transform(data[['유역평균강수', '강우(A지역)', '강우(B지역)', '강우(C지역)', '강우(D지역)', '수위(E지역)', '수위(D지역)']][0:2891]) \n",
    "X_data1 = X_scaler.fit_transform(data[['유역평균강수', '강우(A지역)', '강우(B지역)', '강우(C지역)', '강우(D지역)', '수위(E지역)', '수위(D지역)']])\n",
    "Y_data = Y_scaler.fit_transform(data[['유입량']][0:2891]) # y value\n",
    "Y_data1 = Y_scaler.fit_transform(data[['유입량']]) # y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ts_multi_data_prep(dataset, target, start, end, window, horizon):\n",
    "     X = []\n",
    "     y = []\n",
    "     start = start + window\n",
    "     if end is None:\n",
    "         end = len(dataset) - horizon\n",
    "     for i in range(start, end):\n",
    "         indices = range(i-window, i)\n",
    "         X.append(dataset[indices])\n",
    "         indicey = range(i+1, i+1+horizon)\n",
    "         y.append(target[indicey])\n",
    "     return np.array(X), np.array(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_window = 10\n",
    "horizon = 160 # number of forecasting\n",
    "TRAIN_SPLIT = 2033 # train set number.\n",
    "\n",
    "x_train, y_train = custom_ts_multi_data_prep(X_data, Y_data, 0, TRAIN_SPLIT, hist_window, horizon)\n",
    "x_vali, y_vali = custom_ts_multi_data_prep(X_data, Y_data, TRAIN_SPLIT, None, hist_window, horizon) \n",
    "\n",
    "print(len(y_train),len(y_vali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Multiple window of past history\\n')\n",
    "print(x_train[0])\n",
    "print ('\\n Target horizon\\n')\n",
    "print (y_train[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "import random\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "buffer_size = 150\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
    "val_data = val_data.batch(batch_size).repeat() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "   tf.keras.layers.LSTM(300,input_shape=x_train.shape[-2:]),\n",
    "     tf.keras.layers.Dense(200, activation='tanh'),\n",
    "     tf.keras.layers.Dense(50, activation='tanh'),\n",
    "     tf.keras.layers.Dense(50, activation='tanh'),\n",
    "     tf.keras.layers.Dense(50, activation='tanh'),\n",
    "     tf.keras.layers.Dropout(0.25),\n",
    "     tf.keras.layers.Dense(units=horizon),\n",
    " ])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'LSTM_Multivariate.h5'\n",
    "early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    "callbacks=[early_stopings,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(train_data,epochs=30,steps_per_epoch=50,validation_data=val_data,validation_steps=50,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'validation loss'])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val1 = X_scaler.fit_transform(data[['유역평균강수', '강우(A지역)', '강우(B지역)', '강우(C지역)', '강우(D지역)', '수위(E지역)', '수위(D지역)']][0:2891]) \n",
    "val_rescaled1 = data_val1.reshape(1, data_val1.shape[0], data_val1.shape[1])\n",
    "pred_model = lstm_model.predict(val_rescaled1)\n",
    "pred_model_Inverse = Y_scaler.inverse_transform(pred_model)\n",
    "pred_model_Inverse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_scaler.inverse_transform(y_vali[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model RMSE\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "     def mean_absolute_percentage_error(y_true, y_pred): \n",
    "         y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "         return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "     print('Evaluation metric results:-')\n",
    "     print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "     print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "\n",
    "timeseries_evaluation_metrics_func(y_true, pred_model_Inverse[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(y_true)\n",
    "plt.plot(list(pred_model_Inverse[0]))\n",
    "plt.title(\"true vs predicted\")\n",
    "plt.ylabel(\"Traffic volume\")\n",
    "plt.legend(('true','model predicted'))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홍수 사상 26번 160개 예측\n",
    "data_val = X_scaler.fit_transform(data[['유역평균강수', '강우(A지역)', '강우(C지역)', '수위(E지역)', '수위(D지역)']]) \n",
    "val_rescaled = data_val.reshape(1, data_val.shape[0], data_val.shape[1])\n",
    "pred = lstm_model.predict(val_rescaled)\n",
    "pred_Inverse = Y_scaler.inverse_transform(pred)\n",
    "pred_Inverse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=pd.DataFrame(pred_Inverse)\n",
    "file_name='데이터집단1_LSTM_excepted.xlsx' #예측값 저장할 엑셀 파일 이름.\n",
    "prediction.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot whole y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(data[0:2891]['유입량'])\n",
    "b=pd.DataFrame(pred_Inverse[0],columns=['유입량'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(mod_df)\n",
    "plt.title(\"time series\")\n",
    "plt.ylabel(\"total influx\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d951a4fb713309e6a15ac834ff0fb502c06e5ab8683a64badeae54cb1002e2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
